{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        " Q1.What is Simple Linear Regression?\n",
        " A-Simple Linear Regression is a statistical method used to establish a relationship between two variables: one independent variable (predictor) and one dependent variable (response). The goal is to model this relationship using a straight line, represented by the equation:\n",
        "\n",
        "𝑌\n",
        "=\n",
        "𝑚\n",
        "𝑋\n",
        "+\n",
        "𝑐\n",
        "Y=mX+c\n",
        "\n",
        "𝑌\n",
        "Y: Dependent variable (what we are trying to predict)\n",
        "𝑋\n",
        "X: Independent variable (predictor)\n",
        "𝑚\n",
        "m: Slope of the line (rate of change of\n",
        "𝑌\n",
        "Y with respect to\n",
        "𝑋\n",
        "X)\n",
        "𝑐\n",
        "c: Intercept (value of\n",
        "𝑌\n",
        "Y when\n",
        "𝑋\n",
        "=\n",
        "0\n",
        "X=0)\n",
        "The objective of Simple Linear Regression is to find the values of\n",
        "𝑚\n",
        "m and\n",
        "𝑐\n",
        "c that minimize the differences (errors) between the predicted and actual values of\n",
        "𝑌\n",
        "Y. It assumes a linear relationship between\n",
        "𝑋\n",
        "X and\n",
        "𝑌\n",
        "Y."
      ],
      "metadata": {
        "id": "amwJCRr8IuNu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2.What are the key assumptions of Simple Linear Regression?\n",
        "A-To ensure the validity and reliability of a Simple Linear Regression model, the following key assumptions must be met:\n",
        "\n",
        "Linearity\n",
        "\n",
        "The relationship between the independent variable (\n",
        "𝑋\n",
        "X) and the dependent variable (\n",
        "𝑌\n",
        "Y) is linear.\n",
        "This means\n",
        "𝑌\n",
        "Y can be expressed as\n",
        "𝑌\n",
        "=\n",
        "𝑚\n",
        "𝑋\n",
        "+\n",
        "𝑐\n",
        "Y=mX+c, with deviations captured as errors.\n",
        "Independence of Errors\n",
        "\n",
        "The residuals (errors) should be independent of each other.\n",
        "No patterns or correlations should exist between the errors over time (no autocorrelation).\n",
        "Homoscedasticity\n",
        "\n",
        "The variance of the residuals (errors) is constant across all values of\n",
        "𝑋\n",
        "X.\n",
        "This means the spread of errors should not increase or decrease as\n",
        "𝑋\n",
        "X changes.\n",
        "Normality of Errors\n",
        "\n",
        "The residuals (differences between observed and predicted values) should follow a normal distribution.\n",
        "No Multicollinearity\n",
        "\n",
        "Since Simple Linear Regression involves only one independent variable, multicollinearity (strong correlation between predictors) is not applicable here.\n",
        "No Outliers or Influential Points\n",
        "\n",
        "The data should not have extreme outliers or highly influential points that can disproportionately affect the regression line."
      ],
      "metadata": {
        "id": "9FBqWd9VIuRF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3. What does the coefficient m represent in the equation Y=mX+c?\n",
        "A-In the equation\n",
        "𝑌\n",
        "=\n",
        "𝑚\n",
        "𝑋\n",
        "+\n",
        "𝑐\n",
        "Y=mX+c:\n",
        "\n",
        "𝑚\n",
        "m is the slope of the regression line.\n",
        "It represents the rate of change of the dependent variable (\n",
        "𝑌\n",
        "Y) with respect to the independent variable (\n",
        "𝑋\n",
        "X).\n",
        "Specifically,\n",
        "𝑚\n",
        "m indicates how much\n",
        "𝑌\n",
        "Y is expected to increase (or decrease) for a one-unit increase in\n",
        "𝑋\n",
        "X, assuming all other factors remain constant.\n",
        "Interpretation:\n",
        "If\n",
        "𝑚\n",
        ">\n",
        "0\n",
        "m>0: There is a positive relationship between\n",
        "𝑋\n",
        "X and\n",
        "𝑌\n",
        "Y. As\n",
        "𝑋\n",
        "X increases,\n",
        "𝑌\n",
        "Y also increases.\n",
        "If\n",
        "𝑚\n",
        "<\n",
        "0\n",
        "m<0: There is a negative relationship between\n",
        "𝑋\n",
        "X and\n",
        "𝑌\n",
        "Y. As\n",
        "𝑋\n",
        "X increases,\n",
        "𝑌\n",
        "Y decreases.\n",
        "If\n",
        "𝑚\n",
        "=\n",
        "0\n",
        "m=0:\n",
        "𝑋\n",
        "X has no effect on\n",
        "𝑌\n",
        "Y; the line is horizontal."
      ],
      "metadata": {
        "id": "sxaSjIjSIuVQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4.What does the intercept c represent in the equation Y=mX+c\n",
        "A-In the equation\n",
        "𝑌\n",
        "=\n",
        "𝑚\n",
        "𝑋\n",
        "+\n",
        "𝑐\n",
        "Y=mX+c, the intercept (\n",
        "𝑐\n",
        "c) represents:\n",
        "\n",
        "The value of\n",
        "𝑌\n",
        "Y when\n",
        "𝑋\n",
        "=\n",
        "0\n",
        "X=0:\n",
        "It is the point where the regression line crosses the\n",
        "𝑌\n",
        "Y-axis.\n",
        "\n",
        "Baseline or starting value:\n",
        "The intercept serves as the predicted value of the dependent variable (\n",
        "𝑌\n",
        "Y) in the absence of the independent variable (\n",
        "𝑋\n",
        "X)."
      ],
      "metadata": {
        "id": "T64_c-GJIuZl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q5.- How do we calculate the slope m in Simple Linear Regression?\n",
        "A-The slope (\n",
        "𝑚\n",
        "m) in the equation\n",
        "𝑌\n",
        "=\n",
        "𝑚\n",
        "𝑋\n",
        "+\n",
        "𝑐\n",
        "Y=mX+c can be calculated using the following formula:\n",
        "\n",
        "𝑚\n",
        "=\n",
        "∑\n",
        "(\n",
        "𝑋\n",
        "𝑖\n",
        "−\n",
        "𝑋\n",
        "ˉ\n",
        ")\n",
        "(\n",
        "𝑌\n",
        "𝑖\n",
        "−\n",
        "𝑌\n",
        "ˉ\n",
        ")\n",
        "∑\n",
        "(\n",
        "𝑋\n",
        "𝑖\n",
        "−\n",
        "𝑋\n",
        "ˉ\n",
        ")\n",
        "2\n",
        "m=\n",
        "∑(X\n",
        "i\n",
        "​\n",
        " −\n",
        "X\n",
        "ˉ\n",
        " )\n",
        "2\n",
        "\n",
        "∑(X\n",
        "i\n",
        "​\n",
        " −\n",
        "X\n",
        "ˉ\n",
        " )(Y\n",
        "i\n",
        "​\n",
        " −\n",
        "Y\n",
        "ˉ\n",
        " )\n",
        "​\n",
        "\n"
      ],
      "metadata": {
        "id": "hSpStvaPKevF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q6.What is the purpose of the least squares method in Simple Linear Regression\n",
        "A-The least squares method is a mathematical technique used to find the best-fitting regression line for a set of data points in Simple Linear Regression. The purpose of this method is to minimize the sum of squared residuals (errors), ensuring that the line predicts the dependent variable (\n",
        "𝑌\n",
        "Y) as accurately as possible.\n",
        "\n"
      ],
      "metadata": {
        "id": "XunwLdCoNDGQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q7. How is the coefficient of determination (R²) interpreted in Simple Linear Regression?\n",
        "A-The coefficient of determination (\n",
        "𝑅\n",
        "2\n",
        "R\n",
        "2\n",
        " ) is a statistical measure that indicates how well the regression line explains the variability of the dependent variable (\n",
        "𝑌\n",
        "Y) based on the independent variable (\n",
        "𝑋\n",
        "X).\n",
        "\n",
        "Formula for\n",
        "𝑅\n",
        "2\n",
        "R\n",
        "2\n",
        " :\n",
        "𝑅\n",
        "2\n",
        "=\n",
        "1\n",
        "−\n",
        "SS\n",
        "residual\n",
        "SS\n",
        "total\n",
        "R\n",
        "2\n",
        " =1−\n",
        "SS\n",
        "total\n",
        "​\n",
        "\n",
        "SS\n",
        "residual\n",
        "​\n",
        "\n",
        "​\n",
        "\n",
        "Where:\n",
        "\n",
        "SS\n",
        "residual\n",
        "=\n",
        "∑\n",
        "(\n",
        "𝑌\n",
        "𝑖\n",
        "−\n",
        "𝑌\n",
        "^\n",
        "𝑖\n",
        ")\n",
        "2\n",
        "SS\n",
        "residual\n",
        "​\n",
        " =∑(Y\n",
        "i\n",
        "​\n",
        " −\n",
        "Y\n",
        "^\n",
        "  \n",
        "i\n",
        "​\n",
        " )\n",
        "2\n",
        " : Sum of squared residuals (unexplained variation by the model).\n",
        "SS\n",
        "total\n",
        "=\n",
        "∑\n",
        "(\n",
        "𝑌\n",
        "𝑖\n",
        "−\n",
        "𝑌\n",
        "ˉ\n",
        ")\n",
        "2\n",
        "SS\n",
        "total\n",
        "​\n",
        " =∑(Y\n",
        "i\n",
        "​\n",
        " −\n",
        "Y\n",
        "ˉ\n",
        " )\n",
        "2\n",
        " : Total variation in\n",
        "𝑌\n",
        "Y from its mean.\n",
        "Interpretation of\n",
        "𝑅\n",
        "2\n",
        "R\n",
        "2\n",
        " :\n",
        "Range:\n",
        "𝑅\n",
        "2\n",
        "R\n",
        "2\n",
        "  ranges from 0 to 1.\n",
        "\n",
        "𝑅\n",
        "2\n",
        "=\n",
        "0\n",
        "R\n",
        "2\n",
        " =0: The independent variable (\n",
        "𝑋\n",
        "X) does not explain any of the variation in the dependent variable (\n",
        "𝑌\n",
        "Y).\n",
        "𝑅\n",
        "2\n",
        "=\n",
        "1\n",
        "R\n",
        "2\n",
        " =1: The independent variable (\n",
        "𝑋\n",
        "X) explains all the variation in the dependent variable (\n",
        "𝑌\n",
        "Y).\n",
        "Percentage of Variance Explained:\n",
        "\n",
        "𝑅\n",
        "2\n",
        "R\n",
        "2\n",
        "  represents the proportion of the total variance in\n",
        "𝑌\n",
        "Y that is explained by\n",
        "𝑋\n",
        "X.\n",
        "For example,\n",
        "𝑅\n",
        "2\n",
        "=\n",
        "0.85\n",
        "R\n",
        "2\n",
        " =0.85 means 85% of the variation in\n",
        "𝑌\n",
        "Y is explained by the model, and the remaining 15% is due to other factors or noise.\n",
        "Goodness of Fit:\n",
        "\n",
        "A higher\n",
        "𝑅\n",
        "2\n",
        "R\n",
        "2\n",
        "  value indicates a better fit of the regression model to the data.\n",
        "However, a high\n",
        "𝑅\n",
        "2\n",
        "R\n",
        "2\n",
        "  does not necessarily mean the model is good (e.g., overfitting or ignoring assumptions).\n",
        "Example:\n",
        "Suppose:\n",
        "\n",
        "SS\n",
        "total\n",
        "=\n",
        "100\n",
        "SS\n",
        "total\n",
        "​\n",
        " =100\n",
        "SS\n",
        "residual\n",
        "=\n",
        "20\n",
        "SS\n",
        "residual\n",
        "​\n",
        " =20\n",
        "Then:\n",
        "\n",
        "𝑅\n",
        "2\n",
        "=\n",
        "1\n",
        "−\n",
        "SS\n",
        "residual\n",
        "SS\n",
        "total\n",
        "=\n",
        "1\n",
        "−\n",
        "20\n",
        "100\n",
        "=\n",
        "0.8\n",
        "R\n",
        "2\n",
        " =1−\n",
        "SS\n",
        "total\n",
        "​\n",
        "\n",
        "SS\n",
        "residual\n",
        "​\n",
        "\n",
        "​\n",
        " =1−\n",
        "100\n",
        "20\n",
        "​\n",
        " =0.8\n",
        "Interpretation: The model explains 80% of the variation in\n",
        "𝑌\n",
        "Y, while 20% remains unexplained.\n",
        "\n"
      ],
      "metadata": {
        "id": "cNERtux3OpF1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q8.What is Multiple Linear Regression?\n",
        "A-Multiple Linear Regression is an extension of Simple Linear Regression that models the relationship between a dependent variable (\n",
        "𝑌\n",
        "Y) and two or more independent variables (\n",
        "𝑋\n",
        "1\n",
        ",\n",
        "𝑋\n",
        "2\n",
        ",\n",
        "…\n",
        ",\n",
        "𝑋\n",
        "𝑛\n",
        "X\n",
        "1\n",
        "​\n",
        " ,X\n",
        "2\n",
        "​\n",
        " ,…,X\n",
        "n\n",
        "​\n",
        " ). The goal is to predict\n",
        "𝑌\n",
        "Y based on multiple predictors.\n",
        "\n"
      ],
      "metadata": {
        "id": "N4GwGmyDPJU_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q9. What is the main difference between Simple and Multiple Linear Regression?\n",
        "A-The main difference between Simple Linear Regression and Multiple Linear Regression is the number of independent variables used to predict the dependent variable:\n",
        "\n",
        "Simple Linear Regression:\n",
        "\n",
        "Involves only one independent variable (predictor) and one dependent variable (response).\n",
        "The relationship is modeled by the equation:\n",
        "𝑌\n",
        "=\n",
        "𝑚\n",
        "𝑋\n",
        "+\n",
        "𝑐\n",
        "Y=mX+c\n",
        "where\n",
        "𝑌\n",
        "Y is the dependent variable,\n",
        "𝑋\n",
        "X is the independent variable,\n",
        "𝑚\n",
        "m is the slope, and\n",
        "𝑐\n",
        "c is the intercept.\n",
        "Multiple Linear Regression:\n",
        "\n",
        "Involves two or more independent variables (predictors) to predict the dependent variable.\n",
        "The relationship is modeled by the equation:\n",
        "𝑌\n",
        "=\n",
        "𝑚\n",
        "1\n",
        "𝑋\n",
        "1\n",
        "+\n",
        "𝑚\n",
        "2\n",
        "𝑋\n",
        "2\n",
        "+\n",
        "⋯\n",
        "+\n",
        "𝑚\n",
        "𝑛\n",
        "𝑋\n",
        "𝑛\n",
        "+\n",
        "𝑐\n",
        "Y=m\n",
        "1\n",
        "​\n",
        " X\n",
        "1\n",
        "​\n",
        " +m\n",
        "2\n",
        "​\n",
        " X\n",
        "2\n",
        "​\n",
        " +⋯+m\n",
        "n\n",
        "​\n",
        " X\n",
        "n\n",
        "​\n",
        " +c\n",
        "where\n",
        "𝑋\n",
        "1\n",
        ",\n",
        "𝑋\n",
        "2\n",
        ",\n",
        "…\n",
        ",\n",
        "𝑋\n",
        "𝑛\n",
        "X\n",
        "1\n",
        "​\n",
        " ,X\n",
        "2\n",
        "​\n",
        " ,…,X\n",
        "n\n",
        "​\n",
        "  are the independent variables,\n",
        "𝑚\n",
        "1\n",
        ",\n",
        "𝑚\n",
        "2\n",
        ",\n",
        "…\n",
        ",\n",
        "𝑚\n",
        "𝑛\n",
        "m\n",
        "1\n",
        "​\n",
        " ,m\n",
        "2\n",
        "​\n",
        " ,…,m\n",
        "n\n",
        "​\n",
        "  are their respective coefficients, and\n",
        "𝑐\n",
        "c is the intercept.\n",
        "Key Difference:\n",
        "Simple Linear Regression captures the relationship between a single independent variable and the dependent variable.\n",
        "Multiple Linear Regression examines the combined effect of multiple independent variables on the dependent variable."
      ],
      "metadata": {
        "id": "ijL5ck4FQLzX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q10.What are the key assumptions of Multiple Linear Regression?\n",
        "A-Multiple Linear Regression (MLR) relies on several key assumptions to ensure the validity and reliability of its results. These assumptions are:\n",
        "\n",
        "Linearity:\n",
        "\n",
        "The relationship between the dependent variable and each independent variable is linear. The model should capture this linear relationship accurately.\n",
        "Independence:\n",
        "\n",
        "The observations must be independent of each other. This ensures that the results are not biased due to interdependence in the data.\n",
        "Homoscedasticity:\n",
        "\n",
        "The variance of the residuals (errors) should be constant across all levels of the independent variables. In other words, the spread of residuals should not depend on the values of the predictors.\n",
        "No Multicollinearity:\n",
        "\n",
        "Independent variables should not be highly correlated with each other. High multicollinearity can make it difficult to estimate individual regression coefficients accurately.\n",
        "Normality of Residuals:\n",
        "\n",
        "The residuals (differences between observed and predicted values) should be approximately normally distributed. This is important for hypothesis testing and confidence interval estimation.\n",
        "No Autocorrelation:\n",
        "\n",
        "The residuals should not show patterns of correlation with each other, especially in time-series data. Autocorrelation can lead to incorrect inferences.\n",
        "Measurement Accuracy:\n",
        "\n",
        "The independent variables should be measured accurately and without error, as errors in measurements can lead to biased estimates.\n",
        "Sample Size:\n",
        "\n",
        "There should be a sufficient number of observations relative to the number of independent variables to ensure stable and reliable results. A common rule of thumb is at least 10-20 observations per predictor.\n",
        "Addressing violations of these assumptions (e.g., transforming variables, removing multicollinearity, or using robust regression techniques) can improve model performance and interpretation."
      ],
      "metadata": {
        "id": "ABIEezHMQYud"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q11. What is heteroscedasticity, and how does it affect the results of a Multiple Linear Regression model?\n",
        "A-Heteroscedasticity refers to the situation where the variance of the residuals (errors) is not constant across all levels of the independent variables. In a scatter plot of residuals versus predicted values, heteroscedasticity often appears as a funnel shape, where the spread of residuals increases or decreases as the predicted values change.\n",
        "\n",
        "In simpler terms:\n",
        "\n",
        "Homoscedasticity: The residuals have the same spread (variance) throughout.\n",
        "Heteroscedasticity: The residuals have varying spread, which violates one of the key assumptions of Multiple Linear Regression.\n",
        "Effects of Heteroscedasticity:\n",
        "Inefficient Estimates:\n",
        "\n",
        "Ordinary Least Squares (OLS) regression assumes constant variance of residuals. Heteroscedasticity can result in inefficient parameter estimates, meaning the coefficients may still be unbiased but not the most precise.\n",
        "Misleading Significance Tests:\n",
        "\n",
        "The standard errors of the coefficients may be underestimated or overestimated, leading to incorrect p-values and confidence intervals. This can result in misleading conclusions about the significance of predictors.\n",
        "Reduced Predictive Power:\n",
        "\n",
        "A model with heteroscedasticity may perform poorly in prediction as it does not properly account for the changing variance.\n",
        "Violates Model Assumptions:\n",
        "\n",
        "Heteroscedasticity directly violates the homoscedasticity assumption, which undermines the reliability of the model's results.\n",
        "Addressing Heteroscedasticity:\n",
        "Transform the Dependent Variable:\n",
        "\n",
        "Use logarithmic, square root, or other transformations to stabilize variance.\n",
        "Weighted Least Squares (WLS):\n",
        "\n",
        "Assign weights to observations inversely proportional to the variance of their residuals to account for heteroscedasticity.\n",
        "Robust Standard Errors:\n",
        "\n",
        "Use heteroscedasticity-consistent standard errors (e.g., White’s robust standard errors) to correct the issue without transforming the data.\n",
        "Reevaluate Model Specification:\n",
        "\n",
        "Investigate whether important predictors are missing or if the functional form of the model is incorrect.\n",
        "Visualization:\n",
        "\n",
        "Use residual plots to identify and diagnose heteroscedasticity.\n",
        "Addressing heteroscedasticity is critical to ensure the accuracy and reliability of regression analysis."
      ],
      "metadata": {
        "id": "5Sui6HVJRf79"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q12.How can you improve a Multiple Linear Regression model with high multicollinearity?\n",
        "A-Multicollinearity occurs when two or more independent variables in a Multiple Linear Regression model are highly correlated. This makes it difficult to determine the individual effect of each variable on the dependent variable, as the coefficients become unstable and sensitive to small changes in the data.\n",
        "\n",
        "Techniques to Improve the Model:\n",
        "Remove Highly Correlated Predictors:\n",
        "\n",
        "Use tools like a correlation matrix or Variance Inflation Factor (VIF) to identify highly correlated variables.\n",
        "Drop one of the variables that are strongly correlated to reduce redundancy.\n",
        "Combine Correlated Variables:\n",
        "\n",
        "Combine highly correlated variables into a single feature using aggregation methods (e.g., averaging) or Principal Component Analysis (PCA) to reduce dimensionality.\n",
        "Feature Selection:\n",
        "\n",
        "Use techniques such as:\n",
        "Stepwise Regression (forward or backward elimination).\n",
        "Regularization (Lasso regression automatically selects important variables).\n",
        "Focus only on predictors that significantly contribute to the model.\n",
        "Center the Variables (Mean-Centering):\n",
        "\n",
        "Subtract the mean from each predictor to reduce the effects of multicollinearity caused by interaction terms or polynomial terms.\n",
        "Use Regularization Techniques:\n",
        "\n",
        "Apply methods like:\n",
        "Lasso Regression (L1 regularization): Shrinks some coefficients to zero, effectively removing unimportant predictors.\n",
        "Ridge Regression (L2 regularization): Penalizes large coefficients to stabilize the model.\n",
        "Elastic Net Regression: Combines Lasso and Ridge penalties.\n",
        "Increase Sample Size:\n",
        "\n",
        "If possible, increase the number of observations to reduce the impact of multicollinearity on the coefficient estimates.\n",
        "Domain Knowledge:\n",
        "\n",
        "Use prior knowledge of the domain to decide which variables are essential and should remain in the model.\n",
        "Partial Least Squares (PLS):\n",
        "\n",
        "PLS regression can handle multicollinearity by finding a new set of uncorrelated components and fitting the regression on them.\n",
        "Detecting Multicollinearity:\n",
        "Variance Inflation Factor (VIF):\n",
        "Compute the VIF for each predictor. A VIF value > 10 indicates high multicollinearity.\n",
        "Condition Number:\n",
        "A condition number > 30 suggests multicollinearity."
      ],
      "metadata": {
        "id": "J0aP9tm2R8vF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q13.What are some common techniques for transforming categorical variables for use in regression models?\n",
        "A-Categorical variables cannot be directly used in regression models, as these models rely on numerical input. To include categorical variables in regression, they need to be transformed into a numerical format. Below are some common techniques for this transformation:\n",
        "\n",
        "1. One-Hot Encoding:\n",
        "Converts each category into a separate binary column (0 or 1).\n",
        "Used for nominal (unordered) categorical variables.\n",
        "Example:\n",
        "If a variable \"Color\" has values\n",
        "{\n",
        "Red, Blue, Green\n",
        "}\n",
        "{Red, Blue, Green}:\n",
        "Red\n",
        "→\n",
        "[\n",
        "1\n",
        ",\n",
        "0\n",
        ",\n",
        "0\n",
        "]\n",
        ",\n",
        " Blue\n",
        "→\n",
        "[\n",
        "0\n",
        ",\n",
        "1\n",
        ",\n",
        "0\n",
        "]\n",
        ",\n",
        " Green\n",
        "→\n",
        "[\n",
        "0\n",
        ",\n",
        "0\n",
        ",\n",
        "1\n",
        "]\n",
        "Red→[1,0,0], Blue→[0,1,0], Green→[0,0,1]\n",
        "2. Label Encoding:\n",
        "Assigns a unique integer to each category.\n",
        "Suitable for ordinal (ordered) categorical variables.\n",
        "Example:\n",
        "If a variable \"Size\" has values\n",
        "{\n",
        "Small, Medium, Large\n",
        "}\n",
        "{Small, Medium, Large}:\n",
        "Small\n",
        "→\n",
        "0\n",
        ",\n",
        " Medium\n",
        "→\n",
        "1\n",
        ",\n",
        " Large\n",
        "→\n",
        "2\n",
        "Small→0, Medium→1, Large→2\n",
        "Caution: Not ideal for nominal variables, as it may imply a hierarchy.\n",
        "3. Ordinal Encoding:\n",
        "Similar to label encoding but explicitly respects the order of categories.\n",
        "Example:\n",
        "If a variable \"Education Level\" has values\n",
        "{\n",
        "High School, Bachelor, Master, PhD\n",
        "}\n",
        "{High School, Bachelor, Master, PhD}:\n",
        "High School\n",
        "→\n",
        "1\n",
        ",\n",
        " Bachelor\n",
        "→\n",
        "2\n",
        ",\n",
        " Master\n",
        "→\n",
        "3\n",
        ",\n",
        " PhD\n",
        "→\n",
        "4\n",
        "High School→1, Bachelor→2, Master→3, PhD→4\n",
        "4. Binary Encoding:\n",
        "Combines the properties of label encoding and one-hot encoding by representing categories as binary numbers.\n",
        "Example:\n",
        "For categories\n",
        "{\n",
        "𝐴\n",
        ",\n",
        "𝐵\n",
        ",\n",
        "𝐶\n",
        ",\n",
        "𝐷\n",
        "}\n",
        "{A,B,C,D}:\n",
        "𝐴\n",
        "→\n",
        "00\n",
        ",\n",
        "\n",
        "𝐵\n",
        "→\n",
        "01\n",
        ",\n",
        "\n",
        "𝐶\n",
        "→\n",
        "10\n",
        ",\n",
        "\n",
        "𝐷\n",
        "→\n",
        "11\n",
        "A→00, B→01, C→10, D→11\n",
        "5. Frequency Encoding:\n",
        "Assigns each category the frequency of its occurrence in the dataset.\n",
        "Example:\n",
        "If \"City\" has values\n",
        "{\n",
        "NY (50), LA (30), SF (20)\n",
        "}\n",
        "{NY (50), LA (30), SF (20)}:\n",
        "NY\n",
        "→\n",
        "50\n",
        ",\n",
        " LA\n",
        "→\n",
        "30\n",
        ",\n",
        " SF\n",
        "→\n",
        "20\n",
        "NY→50, LA→30, SF→20\n",
        "6. Target Encoding:\n",
        "Replaces categories with the mean of the target variable for each category.\n",
        "Example:\n",
        "If \"City\" predicts \"Sales\" (\n",
        "𝑌\n",
        "Y), calculate the average sales for each city:\n",
        "City NY: Avg(Sales)\n",
        "=\n",
        "100\n",
        ",\n",
        " City LA: Avg(Sales)\n",
        "=\n",
        "80\n",
        ",\n",
        " City SF: Avg(Sales)\n",
        "=\n",
        "60\n",
        "City NY: Avg(Sales)=100, City LA: Avg(Sales)=80, City SF: Avg(Sales)=60\n",
        "7. Dummy Encoding:\n",
        "Similar to one-hot encoding, but one category is dropped to avoid the dummy variable trap (perfect multicollinearity).\n",
        "Example:\n",
        "For \"Color\" with values\n",
        "{\n",
        "Red, Blue, Green\n",
        "}\n",
        "{Red, Blue, Green}:\n",
        "Only two columns are created:\n",
        "Red\n",
        "→\n",
        "[\n",
        "1\n",
        ",\n",
        "0\n",
        "]\n",
        ",\n",
        " Blue\n",
        "→\n",
        "[\n",
        "0\n",
        ",\n",
        "1\n",
        "]\n",
        ",\n",
        " Green\n",
        "→\n",
        "[\n",
        "0\n",
        ",\n",
        "0\n",
        "]\n",
        "Red→[1,0], Blue→[0,1], Green→[0,0]\n"
      ],
      "metadata": {
        "id": "NjyCRmx1T_OB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q14.- What is the role of interaction terms in Multiple Linear Regression?\n",
        "A-Interaction terms in a Multiple Linear Regression model capture the combined effect of two or more independent variables on the dependent variable. These terms allow the model to account for scenarios where the effect of one independent variable on the dependent variable depends on the value of another independent variable.\n",
        "\n",
        "Role of Interaction Terms:\n",
        "Capture Non-Additive Relationships:\n",
        "\n",
        "In standard regression, the effect of independent variables is assumed to be additive. Interaction terms model cases where the relationship is not additive.\n",
        "Example: If variables\n",
        "𝑋\n",
        "1\n",
        "X\n",
        "1\n",
        "​\n",
        "  (Hours Studied) and\n",
        "𝑋\n",
        "2\n",
        "X\n",
        "2\n",
        "​\n",
        "  (Sleep) interact, their combined effect on\n",
        "𝑌\n",
        "Y (Exam Score) may be greater or smaller than their individual contributions.\n",
        "Improve Model Accuracy:\n",
        "\n",
        "Including interaction terms can improve the model's ability to explain variance in the dependent variable, particularly when there is a true interaction effect in the data.\n",
        "Provide Insight into Complex Relationships:\n",
        "\n",
        "Interaction terms reveal whether and how two variables jointly influence the outcome. This is useful for understanding complex dependencies.\n",
        "Test Hypotheses:\n",
        "\n",
        "Interaction terms can help test specific hypotheses about relationships between variables, such as whether the effect of one variable depends on the level of another.\n"
      ],
      "metadata": {
        "id": "soSVl2kXUsJF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q15.- How can the interpretation of intercept differ between Simple and Multiple Linear Regression?\n",
        "A-The interpretation of the intercept (\n",
        "𝑐\n",
        "c) varies depending on whether it is in a Simple Linear Regression or a Multiple Linear Regression model:\n",
        "\n",
        "1. In Simple Linear Regression:\n",
        "The intercept represents the predicted value of the dependent variable (Y) when the independent variable (\n",
        "𝑋\n",
        "X) is equal to zero.\n",
        "\n",
        "Equation:\n",
        "𝑌\n",
        "=\n",
        "𝑚\n",
        "𝑋\n",
        "+\n",
        "𝑐\n",
        "Y=mX+c\n",
        "\n",
        "Interpretation:\n",
        "If\n",
        "𝑋\n",
        "=\n",
        "0\n",
        "X=0, then\n",
        "𝑌\n",
        "=\n",
        "𝑐\n",
        "Y=c.\n",
        "It indicates the starting value of\n",
        "𝑌\n",
        "Y when there is no influence from\n",
        "𝑋\n",
        "X.\n",
        "\n",
        "Example:\n",
        "If the model is predicting weight (\n",
        "𝑌\n",
        "Y) based on height (\n",
        "𝑋\n",
        "X):\n",
        "Weight\n",
        "=\n",
        "0.5\n",
        "×\n",
        "Height\n",
        "+\n",
        "50\n",
        "Weight=0.5×Height+50\n",
        "Here, the intercept (50) is the predicted weight when height is zero. While this might not make practical sense, it is mathematically valid.\n",
        "\n",
        "2. In Multiple Linear Regression:\n",
        "The intercept represents the predicted value of the dependent variable (Y) when all independent variables are equal to zero.\n",
        "\n",
        "Equation:\n",
        "𝑌\n",
        "=\n",
        "𝑚\n",
        "1\n",
        "𝑋\n",
        "1\n",
        "+\n",
        "𝑚\n",
        "2\n",
        "𝑋\n",
        "2\n",
        "+\n",
        "⋯\n",
        "+\n",
        "𝑚\n",
        "𝑛\n",
        "𝑋\n",
        "𝑛\n",
        "+\n",
        "𝑐\n",
        "Y=m\n",
        "1\n",
        "​\n",
        " X\n",
        "1\n",
        "​\n",
        " +m\n",
        "2\n",
        "​\n",
        " X\n",
        "2\n",
        "​\n",
        " +⋯+m\n",
        "n\n",
        "​\n",
        " X\n",
        "n\n",
        "​\n",
        " +c\n",
        "\n",
        "Interpretation:\n",
        "If\n",
        "𝑋\n",
        "1\n",
        ",\n",
        "𝑋\n",
        "2\n",
        ",\n",
        "…\n",
        ",\n",
        "𝑋\n",
        "𝑛\n",
        "=\n",
        "0\n",
        "X\n",
        "1\n",
        "​\n",
        " ,X\n",
        "2\n",
        "​\n",
        " ,…,X\n",
        "n\n",
        "​\n",
        " =0, then\n",
        "𝑌\n",
        "=\n",
        "𝑐\n",
        "Y=c.\n",
        "It is the baseline value of\n",
        "𝑌\n",
        "Y when no predictors contribute to the outcome.\n",
        "\n",
        "Example:\n",
        "For a model predicting salary based on education level (\n",
        "𝑋\n",
        "1\n",
        "X\n",
        "1\n",
        "​\n",
        " ) and years of experience (\n",
        "𝑋\n",
        "2\n",
        "X\n",
        "2\n",
        "​\n",
        " ):\n",
        "Salary\n",
        "=\n",
        "2000\n",
        "×\n",
        "Education Level\n",
        "+\n",
        "5000\n",
        "×\n",
        "Experience\n",
        "+\n",
        "25000\n",
        "Salary=2000×Education Level+5000×Experience+25000\n",
        "Here, the intercept (25,000) is the predicted salary when both education level and experience are zero.\n",
        "\n",
        "Key Differences in Interpretation:\n",
        "Simple Linear Regression:\n",
        "\n",
        "The intercept typically represents a straightforward baseline value when the single predictor is zero.\n",
        "Its interpretation is easier to understand but may not always be practical (e.g., height = 0).\n",
        "Multiple Linear Regression:\n",
        "\n",
        "The intercept depends on multiple predictors being zero simultaneously, which may not always be realistic or meaningful.\n",
        "Its interpretation often depends on the context of the predictors.\n",
        "Considerations:\n",
        "Practical Meaning:\n",
        "In both cases, if the scenario where all predictors are zero is unrealistic or outside the data range, the intercept's interpretation may have limited practical significance.\n",
        "\n",
        "Centering Variables:\n",
        "In Multiple Linear Regression, centering the predictors (subtracting their mean) can make the intercept more interpretable. It then represents the predicted value of\n",
        "𝑌\n",
        "Y when all predictors are at their mean values.\n",
        "\n",
        "By understanding the context of the data and predictors, the intercept's role in the regression model can be appropriately interpreted.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2UyGYkwJVB8J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q16.What is the significance of the slope in regression analysis, and how does it affect predictions?\n",
        "A-1. Definition of the Slope:\n",
        "The slope represents the rate of change of the dependent variable (\n",
        "𝑌\n",
        "Y) with respect to the independent variable(s) (\n",
        "𝑋\n",
        "X). It indicates how much\n",
        "𝑌\n",
        "Y changes for a one-unit increase in\n",
        "𝑋\n",
        "X, assuming all other variables remain constant in the case of Multiple Linear Regression.\n",
        "\n",
        "2. Significance of the Slope:\n",
        "The slope is significant because it quantifies the strength and direction of the relationship between the predictor(s) and the outcome variable.\n",
        "\n",
        "In Simple Linear Regression:\n",
        "Equation:\n",
        "𝑌\n",
        "=\n",
        "𝑚\n",
        "𝑋\n",
        "+\n",
        "𝑐\n",
        "Y=mX+c\n",
        "𝑚\n",
        "m: The slope coefficient.\n",
        "Significance:\n",
        "A positive slope (\n",
        "𝑚\n",
        ">\n",
        "0\n",
        "m>0) indicates that\n",
        "𝑌\n",
        "Y increases as\n",
        "𝑋\n",
        "X increases.\n",
        "A negative slope (\n",
        "𝑚\n",
        "<\n",
        "0\n",
        "m<0) indicates that\n",
        "𝑌\n",
        "Y decreases as\n",
        "𝑋\n",
        "X increases.\n",
        "If\n",
        "𝑚\n",
        "=\n",
        "0\n",
        "m=0, there is no linear relationship between\n",
        "𝑋\n",
        "X and\n",
        "𝑌\n",
        "Y.\n",
        "Example:\n",
        "If\n",
        "𝑌\n",
        "=\n",
        "2\n",
        "𝑋\n",
        "+\n",
        "5\n",
        "Y=2X+5:\n",
        "\n",
        "For every one-unit increase in\n",
        "𝑋\n",
        "X,\n",
        "𝑌\n",
        "Y increases by 2.\n",
        "In Multiple Linear Regression:\n",
        "Equation:\n",
        "𝑌\n",
        "=\n",
        "𝑚\n",
        "1\n",
        "𝑋\n",
        "1\n",
        "+\n",
        "𝑚\n",
        "2\n",
        "𝑋\n",
        "2\n",
        "+\n",
        "⋯\n",
        "+\n",
        "𝑚\n",
        "𝑛\n",
        "𝑋\n",
        "𝑛\n",
        "+\n",
        "𝑐\n",
        "Y=m\n",
        "1\n",
        "​\n",
        " X\n",
        "1\n",
        "​\n",
        " +m\n",
        "2\n",
        "​\n",
        " X\n",
        "2\n",
        "​\n",
        " +⋯+m\n",
        "n\n",
        "​\n",
        " X\n",
        "n\n",
        "​\n",
        " +c\n",
        "Each\n",
        "𝑚\n",
        "𝑖\n",
        "m\n",
        "i\n",
        "​\n",
        "  represents the slope for the corresponding independent variable\n",
        "𝑋\n",
        "𝑖\n",
        "X\n",
        "i\n",
        "​\n",
        " .\n",
        "Significance:\n",
        "Each slope measures the partial effect of its associated\n",
        "𝑋\n",
        "𝑖\n",
        "X\n",
        "i\n",
        "​\n",
        "  on\n",
        "𝑌\n",
        "Y, holding all other predictors constant.\n",
        "Example:\n",
        "If\n",
        "𝑌\n",
        "=\n",
        "3\n",
        "𝑋\n",
        "1\n",
        "+\n",
        "5\n",
        "𝑋\n",
        "2\n",
        "+\n",
        "10\n",
        "Y=3X\n",
        "1\n",
        "​\n",
        " +5X\n",
        "2\n",
        "​\n",
        " +10:\n",
        "\n",
        "𝑚\n",
        "1\n",
        "=\n",
        "3\n",
        "m\n",
        "1\n",
        "​\n",
        " =3: For every one-unit increase in\n",
        "𝑋\n",
        "1\n",
        "X\n",
        "1\n",
        "​\n",
        " ,\n",
        "𝑌\n",
        "Y increases by 3, assuming\n",
        "𝑋\n",
        "2\n",
        "X\n",
        "2\n",
        "​\n",
        "  remains unchanged.\n",
        "𝑚\n",
        "2\n",
        "=\n",
        "5\n",
        "m\n",
        "2\n",
        "​\n",
        " =5: For every one-unit increase in\n",
        "𝑋\n",
        "2\n",
        "X\n",
        "2\n",
        "​\n",
        " ,\n",
        "𝑌\n",
        "Y increases by 5, assuming\n",
        "𝑋\n",
        "1\n",
        "X\n",
        "1\n",
        "​\n",
        "  remains unchanged.\n",
        "How the Slope Affects Predictions:\n",
        "Magnitude of the Effect:\n",
        "\n",
        "The absolute value of the slope indicates the strength of the relationship between\n",
        "𝑋\n",
        "X and\n",
        "𝑌\n",
        "Y.\n",
        "Larger slopes correspond to greater changes in\n",
        "𝑌\n",
        "Y for a unit change in\n",
        "𝑋\n",
        "X.\n",
        "Direction of the Relationship:\n",
        "\n",
        "Positive slopes indicate a direct relationship (as\n",
        "𝑋\n",
        "X increases,\n",
        "𝑌\n",
        "Y increases).\n",
        "Negative slopes indicate an inverse relationship (as\n",
        "𝑋\n",
        "X increases,\n",
        "𝑌\n",
        "Y decreases).\n",
        "Predictive Power:\n",
        "\n",
        "The slope allows the regression model to predict\n",
        "𝑌\n",
        "Y for any given value of\n",
        "𝑋\n",
        "X.\n",
        "Interpreting the Slope in Context:\n",
        "The meaning of the slope depends on the context of the problem. For instance:\n",
        "\n",
        "In an economics model: If\n",
        "𝑌\n",
        "Y is demand and\n",
        "𝑋\n",
        "X is price, a negative slope indicates that demand decreases as price increases.\n",
        "In healthcare: If\n",
        "𝑌\n",
        "Y is blood pressure and\n",
        "𝑋\n",
        "X is medication dosage, a negative slope suggests that higher doses lower blood pressure.\n",
        "Statistical Significance of the Slope:\n",
        "The slope's p-value tests whether it is significantly different from zero:\n",
        "A small p-value (e.g.,\n",
        "<\n",
        "0.05\n",
        "<0.05) suggests the slope is statistically significant, meaning\n",
        "𝑋\n",
        "X has a meaningful effect on\n",
        "𝑌\n",
        "Y.\n",
        "Understanding the slope's significance and its effect on predictions helps in interpreting the relationship between variables and making informed decisions.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bmxBtO-WVajD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q17.How does the intercept in a regression model provide context for the relationship between variables?\n",
        "A-The intercept in a regression model represents the predicted value of the dependent variable (\n",
        "𝑌\n",
        "Y) when all independent variables (\n",
        "𝑋\n",
        "X) are equal to zero. It provides important contextual information about the baseline or starting point of the relationship between variables.\n",
        "\n",
        "1. In Simple Linear Regression:\n",
        "Equation:\n",
        "𝑌\n",
        "=\n",
        "𝑚\n",
        "𝑋\n",
        "+\n",
        "𝑐\n",
        "Y=mX+c\n",
        "The intercept (\n",
        "𝑐\n",
        "c) is the predicted value of\n",
        "𝑌\n",
        "Y when\n",
        "𝑋\n",
        "=\n",
        "0\n",
        "X=0.\n",
        "Context:\n",
        "It serves as the baseline value of\n",
        "𝑌\n",
        "Y before any effect of the independent variable (\n",
        "𝑋\n",
        "X) is applied.\n",
        "Example:\n",
        "If\n",
        "𝑌\n",
        "=\n",
        "2\n",
        "𝑋\n",
        "+\n",
        "5\n",
        "Y=2X+5, then when\n",
        "𝑋\n",
        "=\n",
        "0\n",
        "X=0,\n",
        "𝑌\n",
        "=\n",
        "5\n",
        "Y=5. The intercept (\n",
        "5\n",
        "5) is the value of\n",
        "𝑌\n",
        "Y when there is no input from\n",
        "𝑋\n",
        "X.\n"
      ],
      "metadata": {
        "id": "VIynQEloVuuu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q18.What are the limitations of using R² as a sole measure of model performance?\n",
        "A-Limitations of\n",
        "𝑅\n",
        "2\n",
        "R\n",
        "2\n",
        "  (Coefficient of Determination):\n",
        "Does Not Indicate Model Fit Quality in Isolation:\n",
        "\n",
        "A high\n",
        "𝑅\n",
        "2\n",
        "R\n",
        "2\n",
        "  does not necessarily mean the model fits the data well. It only measures the proportion of variance in the dependent variable that is explained by the independent variable(s). The actual fit could still be poor if important patterns or outliers are missed.\n",
        "Not Applicable for Non-Linear Models:\n",
        "\n",
        "𝑅\n",
        "2\n",
        "R\n",
        "2\n",
        "  assumes linear relationships between variables. It may not accurately measure performance for non-linear models, even if they provide a better fit to the data.\n",
        "Overfitting in Complex Models:\n",
        "\n",
        "Adding more predictors to the model always increases\n",
        "𝑅\n",
        "2\n",
        "R\n",
        "2\n",
        " , even if those predictors are not meaningful. This can lead to overfitting, where the model performs well on the training data but poorly on unseen data.\n",
        "Ignores Predictive Accuracy:\n",
        "\n",
        "𝑅\n",
        "2\n",
        "R\n",
        "2\n",
        "  evaluates how well the model explains the variance but says nothing about the model's ability to make accurate predictions, especially for unseen data. Metrics like RMSE, MAE, or cross-validation errors are more relevant for predictive accuracy.\n",
        "No Information on Residuals:\n",
        "\n",
        "𝑅\n",
        "2\n",
        "R\n",
        "2\n",
        "  does not provide information about residuals (e.g., whether errors are homoscedastic or normally distributed). These are critical to evaluating whether regression assumptions are met.\n",
        "Insensitive to Scale:\n",
        "\n",
        "𝑅\n",
        "2\n",
        "R\n",
        "2\n",
        "  does not account for the scale of dependent variables. A model with a high\n",
        "𝑅\n",
        "2\n",
        "R\n",
        "2\n",
        "  might still be unsuitable if the magnitude of errors (e.g., as seen in RMSE) is too large.\n",
        "Potential Misinterpretation of Low\n",
        "𝑅\n",
        "2\n",
        "R\n",
        "2\n",
        " :\n",
        "\n",
        "In some cases (e.g., predicting human behavior), even a low\n",
        "𝑅\n",
        "2\n",
        "R\n",
        "2\n",
        "  can still indicate a useful model because real-world variability is hard to explain fully.\n",
        "Does Not Account for Adjusted Complexity:\n",
        "\n",
        "𝑅\n",
        "2\n",
        "R\n",
        "2\n",
        "  does not penalize the model for using too many predictors. Adjusted\n",
        "𝑅\n",
        "2\n",
        "R\n",
        "2\n",
        "  is a better alternative as it adjusts for the number of predictors in the model."
      ],
      "metadata": {
        "id": "PyWdOIIGIVq3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q19. How would you interpret a large standard error for a regression coefficient?\n",
        "A-Interpretation of a Large Standard Error for a Regression Coefficient:\n",
        "Definition of Standard Error (SE):\n",
        "\n",
        "The standard error of a regression coefficient measures the precision of the estimated coefficient.\n",
        "A smaller SE indicates more confidence in the coefficient, while a larger SE suggests greater uncertainty.\n",
        "Implications of a Large Standard Error:\n",
        "\n",
        "Low Precision in Estimates: A large SE indicates that the coefficient estimate varies significantly across different samples, implying that it may not reliably capture the true effect.\n",
        "Insignificant Predictors: If the SE is large relative to the size of the coefficient, the variable might not be statistically significant (its p-value will likely be high).\n",
        "Multicollinearity: High SEs can result from multicollinearity (strong correlation between independent variables), making it difficult to isolate the unique contribution of each variable.\n",
        "Small Sample Size: A small sample size can increase the variability of estimates, leading to larger SEs.\n",
        "Poor Model Fit: A high level of noise in the data or a poorly fitting model can also contribute to large SEs.\n",
        "Practical Example: Consider the regression equation:\n",
        "𝑌\n",
        "=\n",
        "2.5\n",
        "𝑋\n",
        "1\n",
        "+\n",
        "0.1\n",
        "𝑋\n",
        "2\n",
        "+\n",
        "𝑐\n",
        "Y=2.5X\n",
        "1\n",
        "​\n",
        " +0.1X\n",
        "2\n",
        "​\n",
        " +c\n",
        "If the SE for\n",
        "𝑋\n",
        "1\n",
        "X\n",
        "1\n",
        "​\n",
        "  is 0.1 and for\n",
        "𝑋\n",
        "2\n",
        "X\n",
        "2\n",
        "​\n",
        "  is 1.5:\n",
        "\n",
        "The coefficient of\n",
        "𝑋\n",
        "1\n",
        "X\n",
        "1\n",
        "​\n",
        "  is more precise, and we are confident in its effect.\n",
        "The coefficient of\n",
        "𝑋\n",
        "2\n",
        "X\n",
        "2\n",
        "​\n",
        "  has a large SE relative to its value, indicating uncertainty or potential insignificance.\n",
        "Actions to Address Large SEs:\n",
        "\n",
        "Increase Sample Size: Collect more data to improve estimate precision.\n",
        "Address Multicollinearity: Remove or combine highly correlated variables using techniques like principal component analysis (PCA) or variance inflation factor (VIF) analysis.\n",
        "Simplify the Model: Eliminate irrelevant or noisy variables.\n",
        "Improve Data Quality: Reduce measurement errors or include additional relevant predictors."
      ],
      "metadata": {
        "id": "1ViwAcWoJjFh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q20.How can heteroscedasticity be identified in residual plots, and why is it important to address it?\n",
        "A-Identifying Heteroscedasticity in Residual Plots:\n",
        "What is Heteroscedasticity?\n",
        "\n",
        "Heteroscedasticity occurs when the variance of residuals (errors) is not constant across all levels of the independent variable(s). This violates one of the key assumptions of linear regression.\n",
        "Residual Plot for Detection:\n",
        "\n",
        "A residual plot is a graph where residuals are plotted on the\n",
        "𝑦\n",
        "y-axis, and predicted values (or an independent variable) are on the\n",
        "𝑥\n",
        "x-axis.\n",
        "Signs of Heteroscedasticity:\n",
        "Residuals exhibit a funnel shape (narrow at one end and wide at the other).\n",
        "Residuals show a pattern instead of being randomly scattered.\n",
        "Example:\n",
        "A cone-shaped spread of residuals suggests increasing variance as the value of the predictor increases.\n",
        "Formal Tests for Heteroscedasticity:\n",
        "\n",
        "Breusch-Pagan Test: Checks for a relationship between residuals and independent variables.\n",
        "White Test: Detects heteroscedasticity without specifying a particular pattern.\n",
        "Importance of Addressing Heteroscedasticity:\n",
        "Biased Standard Errors:\n",
        "\n",
        "Heteroscedasticity leads to incorrect estimates of standard errors, making hypothesis tests (e.g., p-values) unreliable.\n",
        "Impact on Coefficient Significance:\n",
        "\n",
        "Even if the coefficients remain unbiased, their significance may be distorted due to incorrect standard error estimates.\n",
        "Suboptimal Predictions:\n",
        "\n",
        "Models with heteroscedasticity may underperform in prediction, particularly for values where variance is high.\n",
        "Misleading R²:\n",
        "\n",
        "Heteroscedasticity can distort the goodness-of-fit measure, leading to over- or underestimation of model performance.\n",
        "Remedies for Heteroscedasticity:\n",
        "Transform the Dependent Variable:\n",
        "\n",
        "Apply transformations like log, square root, or Box-Cox to stabilize the variance.\n",
        "Weighted Least Squares (WLS):\n",
        "\n",
        "Assign weights to observations inversely proportional to their variance.\n",
        "Robust Standard Errors:\n",
        "\n",
        "Use heteroscedasticity-robust standard errors to correct for variability.\n",
        "Re-evaluate the Model:\n",
        "\n",
        "Identify and include missing variables that might explain the changing variance.\n"
      ],
      "metadata": {
        "id": "LVZ7R_GnJwP2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q21.What does it mean if a Multiple Linear Regression model has a high\n",
        "𝑅\n",
        "2\n",
        "R\n",
        "2\n",
        "  but low adjusted\n",
        "𝑅\n",
        "2\n",
        "R\n",
        "2\n",
        " A-𝑅\n",
        "2\n",
        "R\n",
        "2\n",
        " :\n",
        "\n",
        "Measures the proportion of variance in the dependent variable that is explained by the independent variables.\n",
        "Always increases as more variables are added to the model, regardless of their relevance.\n",
        "Adjusted\n",
        "𝑅\n",
        "2\n",
        "R\n",
        "2\n",
        " :\n",
        "\n",
        "Adjusts\n",
        "𝑅\n",
        "2\n",
        "R\n",
        "2\n",
        "  for the number of predictors in the model.\n",
        "Penalizes the addition of irrelevant variables that do not contribute meaningfully to explaining the variance.\n",
        "Formula:\n",
        "Adjusted\n",
        "𝑅\n",
        "2\n",
        "=\n",
        "1\n",
        "−\n",
        "(\n",
        "1\n",
        "−\n",
        "𝑅\n",
        "2\n",
        ")\n",
        "(\n",
        "𝑛\n",
        "−\n",
        "1\n",
        ")\n",
        "𝑛\n",
        "−\n",
        "𝑘\n",
        "−\n",
        "1\n",
        "Adjusted R\n",
        "2\n",
        " =1−\n",
        "n−k−1\n",
        "(1−R\n",
        "2\n",
        " )(n−1)\n",
        "​\n",
        "\n",
        "Where:\n",
        "𝑛\n",
        "n: Number of observations\n",
        "𝑘\n",
        "k: Number of predictors\n",
        "Meaning of High\n",
        "𝑅\n",
        "2\n",
        "R\n",
        "2\n",
        "  but Low Adjusted\n",
        "𝑅\n",
        "2\n",
        "R\n",
        "2\n",
        " :\n",
        "Irrelevant Predictors in the Model:\n",
        "\n",
        "The model includes variables that do not significantly contribute to explaining the dependent variable. These variables inflate\n",
        "𝑅\n",
        "2\n",
        "R\n",
        "2\n",
        "  but reduce adjusted\n",
        "𝑅\n",
        "2\n",
        "R\n",
        "2\n",
        " .\n",
        "Overfitting:\n",
        "\n",
        "Adding too many predictors causes the model to fit the noise in the data, rather than the underlying relationship. This artificially inflates\n",
        "𝑅\n",
        "2\n",
        "R\n",
        "2\n",
        "  while adjusted\n",
        "𝑅\n",
        "2\n",
        "R\n",
        "2\n",
        "  drops due to the penalty for excess variables.\n",
        "Small Sample Size:\n",
        "\n",
        "With a small number of observations, adding more predictors can greatly reduce adjusted\n",
        "𝑅\n",
        "2\n",
        "R\n",
        "2\n",
        " , as the penalty term becomes significant.\n",
        "Low Statistical Significance of Predictors:\n",
        "\n",
        "If predictors are not statistically significant, they may increase\n",
        "𝑅\n",
        "2\n",
        "R\n",
        "2\n",
        "  but not contribute meaningfully, leading to a low adjusted\n",
        "𝑅\n",
        "2\n",
        "R\n",
        "2\n",
        " .\n"
      ],
      "metadata": {
        "id": "sic3F0KQJ7RJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q22.Why is it important to scale variables in Multiple Linear Regression?\n",
        "A-Importance of Scaling Variables in Multiple Linear Regression:\n",
        "Avoids Dominance of Larger Scale Variables:\n",
        "\n",
        "In multiple linear regression, variables with larger scales can dominate those with smaller scales, leading to biased coefficients and inaccurate results.\n",
        "Improves Gradient-Based Optimization:\n",
        "\n",
        "Scaling helps algorithms (like gradient descent) converge faster, as the cost function is better conditioned when all variables are on a similar scale.\n",
        "Prevents Numerical Instability:\n",
        "\n",
        "Variables with vastly different magnitudes can cause numerical issues, leading to unreliable coefficient estimates and poor model performance.\n",
        "Facilitates Coefficient Comparisons:\n",
        "\n",
        "Scaling allows regression coefficients to be compared directly, as they represent the standardized effects of variables on the dependent variable.\n",
        "Reduces Multicollinearity:\n",
        "\n",
        "Variables with large differences in scale can exacerbate multicollinearity issues (high correlation between predictors), destabilizing the model.\n",
        "When Scaling May Be Critical:\n",
        "If Variables Have Different Units:\n",
        "For example, in a model with variables like \"income (in thousands)\" and \"age (in years),\" scaling ensures both contribute proportionally.\n",
        "If Regularization Techniques Are Used:\n",
        "Models like Ridge or Lasso regression are sensitive to feature scaling, as they apply penalties based on the magnitude of coefficients.\n",
        "Common Scaling Methods:\n",
        "Standardization (Z-Score Scaling):\n",
        "\n",
        "Transforms data to have a mean of 0 and a standard deviation of 1:\n",
        "𝑧\n",
        "=\n",
        "𝑥\n",
        "−\n",
        "𝜇\n",
        "𝜎\n",
        "z=\n",
        "σ\n",
        "x−μ\n",
        "​\n",
        "\n",
        "Where\n",
        "𝜇\n",
        "μ is the mean and\n",
        "𝜎\n",
        "σ is the standard deviation.\n",
        "Min-Max Scaling:\n",
        "\n",
        "Scales values to a range between 0 and 1:\n",
        "𝑥\n",
        "scaled\n",
        "=\n",
        "𝑥\n",
        "−\n",
        "min\n",
        "(\n",
        "𝑥\n",
        ")\n",
        "max\n",
        "(\n",
        "𝑥\n",
        ")\n",
        "−\n",
        "min\n",
        "(\n",
        "𝑥\n",
        ")\n",
        "x\n",
        "scaled\n",
        "​\n",
        " =\n",
        "max(x)−min(x)\n",
        "x−min(x)\n",
        "​\n",
        "\n",
        "Max Absolute Scaling:\n",
        "\n",
        "Divides all values by the maximum absolute value in the dataset."
      ],
      "metadata": {
        "id": "Jr8IJf1JKRTV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q23.What is polynomial regression?\n",
        "A-Polynomial regression is a type of regression analysis where the relationship between the independent variable(s) (\n",
        "𝑋\n",
        "X) and the dependent variable (\n",
        "𝑌\n",
        "Y) is modeled as an\n",
        "𝑛\n",
        "n-th degree polynomial. It is an extension of linear regression that captures non-linear relationships by introducing higher-order terms of the independent variable(s).\n",
        "\n",
        "General Equation for Polynomial Regression:\n",
        "For a single variable\n",
        "𝑋\n",
        "X, the equation is:\n",
        "\n",
        "𝑌\n",
        "=\n",
        "𝑏\n",
        "0\n",
        "+\n",
        "𝑏\n",
        "1\n",
        "𝑋\n",
        "+\n",
        "𝑏\n",
        "2\n",
        "𝑋\n",
        "2\n",
        "+\n",
        "𝑏\n",
        "3\n",
        "𝑋\n",
        "3\n",
        "+\n",
        "⋯\n",
        "+\n",
        "𝑏\n",
        "𝑛\n",
        "𝑋\n",
        "𝑛\n",
        "+\n",
        "𝜖\n",
        "Y=b\n",
        "0\n",
        "​\n",
        " +b\n",
        "1\n",
        "​\n",
        " X+b\n",
        "2\n",
        "​\n",
        " X\n",
        "2\n",
        " +b\n",
        "3\n",
        "​\n",
        " X\n",
        "3\n",
        " +⋯+b\n",
        "n\n",
        "​\n",
        " X\n",
        "n\n",
        " +ϵ\n",
        "Where:\n",
        "\n",
        "𝑌\n",
        "Y is the dependent variable.\n",
        "𝑋\n",
        ",\n",
        "𝑋\n",
        "2\n",
        ",\n",
        "𝑋\n",
        "3\n",
        ",\n",
        "…\n",
        ",\n",
        "𝑋\n",
        "𝑛\n",
        "X,X\n",
        "2\n",
        " ,X\n",
        "3\n",
        " ,…,X\n",
        "n\n",
        "  are independent variables raised to increasing powers.\n",
        "𝑏\n",
        "0\n",
        ",\n",
        "𝑏\n",
        "1\n",
        ",\n",
        "𝑏\n",
        "2\n",
        ",\n",
        "…\n",
        ",\n",
        "𝑏\n",
        "𝑛\n",
        "b\n",
        "0\n",
        "​\n",
        " ,b\n",
        "1\n",
        "​\n",
        " ,b\n",
        "2\n",
        "​\n",
        " ,…,b\n",
        "n\n",
        "​\n",
        "  are coefficients.\n",
        "𝜖\n",
        "ϵ is the error term.\n",
        "Key Characteristics:\n",
        "Non-Linear Relationship:\n",
        "\n",
        "While the model can fit non-linear data, the regression is \"linear\" in the sense that it is linear in the coefficients (\n",
        "𝑏\n",
        "0\n",
        ",\n",
        "𝑏\n",
        "1\n",
        ",\n",
        "…\n",
        ",\n",
        "𝑏\n",
        "𝑛\n",
        "b\n",
        "0\n",
        "​\n",
        " ,b\n",
        "1\n",
        "​\n",
        " ,…,b\n",
        "n\n",
        "​\n",
        " ).\n",
        "Flexible Fit:\n",
        "\n",
        "By increasing the degree of the polynomial (\n",
        "𝑛\n",
        "n), the model can fit more complex curves.\n",
        "Overfitting Risk:\n",
        "\n",
        "A high-degree polynomial can overfit the training data, capturing noise rather than the underlying trend.\n",
        "When to Use Polynomial Regression:\n",
        "When the relationship between variables is non-linear but can be approximated with a polynomial function.\n",
        "Examples:\n",
        "Modeling growth patterns.\n",
        "Predicting sales based on non-linear trends.\n",
        "Fitting curves in engineering or scientific data.\n",
        "Advantages:\n",
        "Captures non-linear relationships effectively.\n",
        "Still computationally efficient since it extends linear regression.\n",
        "Disadvantages:\n",
        "Sensitive to outliers, which can distort the curve significantly.\n",
        "Risk of overfitting with high-degree polynomials.\n",
        "Can become unstable for large ranges of\n",
        "𝑋\n",
        "X."
      ],
      "metadata": {
        "id": "EVDBlZI2LF4u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q23.How does polynomial regression differ from linear regression?\n",
        "A-Mathematical Representation:\n",
        "\n",
        "Linear regression fits data to a straight line.\n",
        "Polynomial regression fits data to a curve by adding polynomial terms.\n",
        "Visual Example:\n",
        "\n",
        "Linear regression will fit a line even when the true relationship is non-linear, leading to poor predictions.\n",
        "Polynomial regression can adjust to non-linear trends by fitting a curve.\n",
        "Overfitting in Polynomial Regression:\n",
        "\n",
        "Adding too many polynomial terms can make the model too sensitive to minor variations in data (noise).\n",
        "Example:\n",
        "Linear regression:\n",
        "𝑌\n",
        "=\n",
        "𝑏\n",
        "0\n",
        "+\n",
        "𝑏\n",
        "1\n",
        "𝑋\n",
        "Y=b\n",
        "0\n",
        "​\n",
        " +b\n",
        "1\n",
        "​\n",
        " X\n",
        "Polynomial regression (degree 5):\n",
        "𝑌\n",
        "=\n",
        "𝑏\n",
        "0\n",
        "+\n",
        "𝑏\n",
        "1\n",
        "𝑋\n",
        "+\n",
        "𝑏\n",
        "2\n",
        "𝑋\n",
        "2\n",
        "+\n",
        "𝑏\n",
        "3\n",
        "𝑋\n",
        "3\n",
        "+\n",
        "𝑏\n",
        "4\n",
        "𝑋\n",
        "4\n",
        "+\n",
        "𝑏\n",
        "5\n",
        "𝑋\n",
        "5\n",
        "Y=b\n",
        "0\n",
        "​\n",
        " +b\n",
        "1\n",
        "​\n",
        " X+b\n",
        "2\n",
        "​\n",
        " X\n",
        "2\n",
        " +b\n",
        "3\n",
        "​\n",
        " X\n",
        "3\n",
        " +b\n",
        "4\n",
        "​\n",
        " X\n",
        "4\n",
        " +b\n",
        "5\n",
        "​\n",
        " X\n",
        "5\n",
        "\n",
        "Feature Engineering:\n",
        "\n",
        "Polynomial regression requires transforming the original features into higher powers, making it less interpretable compared to linear regression."
      ],
      "metadata": {
        "id": "o5ZzWbUoL8G_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q24. How does polynomial regression differ from linear regression?\n",
        "A-Linear Regression\n",
        "\n",
        "Assumes a linear relationship: It models the relationship between the dependent variable (y) and independent variable(s) (x) as a straight line.\n",
        "Equation: y = a + bx\n",
        "Simple and interpretable: Easy to understand and explain.\n",
        "Limited to linear relationships: May not accurately capture complex patterns in the data.\n",
        "Polynomial Regression\n",
        "\n",
        "Models non-linear relationships: It models the relationship between the dependent variable (y) and independent variable(s) (x) as a curve.\n",
        "Equation: y = a + b₁x + b₂x² + b₃x³ + ... + bₙxⁿ\n",
        "More flexible: Can capture complex patterns and curves in the data.\n",
        "Risk of overfitting: Higher-degree polynomials can be prone to overfitting, meaning they may fit the training data too well and perform poorly on new data.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aha_Q8EdNLS6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q25.When is polynomial regression used?\n",
        "A-Polynomial regression is used when the relationship between the independent variable(s) and the dependent variable is not linear. Here are some key situations where it's particularly valuable:\n",
        "\n",
        "1. Capturing Non-Linear Trends:\n",
        "\n",
        "Curved Relationships: When the data points don't follow a straight line but exhibit a curved pattern (e.g., U-shaped, parabolic, or more complex curves).\n",
        "Example: Predicting crop yield based on temperature and rainfall. These factors often have a non-linear impact on yield.\n",
        "2. Improving Model Fit:\n",
        "\n",
        "Underfitting: If a linear regression model doesn't adequately capture the underlying patterns in the data, leading to high prediction errors, polynomial regression can provide a better fit.\n",
        "3. Exploring Complex Relationships:\n",
        "\n",
        "Identifying Non-Linear Interactions: Polynomial regression can help uncover hidden non-linear relationships between variables that might not be apparent with linear models.\n",
        "4. Specific Applications:\n",
        "\n",
        "Predicting Disease Spread: Modeling the spread of diseases like epidemics, which often exhibit non-linear growth patterns.\n",
        "Analyzing Financial Data: Forecasting stock prices or other financial time series, where trends can be non-linear.\n",
        "Engineering and Physics: Modeling physical phenomena that involve non-linear relationships, such as the behavior of certain materials or the trajectory of projectiles.\n",
        "Key Considerations:\n",
        "\n",
        "Overfitting: Higher-degree polynomials can be prone to overfitting, meaning they may fit the training data too well but perform poorly on new data. Careful model selection and validation are crucial.\n",
        "Interpretability: As the degree of the polynomial increases, the model becomes more complex and less interpretable.\n",
        "By understanding these situations, you can effectively determine when polynomial regression is the appropriate tool for your data analysis.\n",
        "\n",
        "\n",
        "\n",
        "Sources and related content\n"
      ],
      "metadata": {
        "id": "ht7zrYceNWb5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q26.What is the general equation for polynomial regression?\n",
        "A-y = b₀ + b₁x + b₂x² + ... + bₙxⁿ + ε\n",
        "\n",
        "where:\n",
        "\n",
        "y: is the dependent variable (the variable you're trying to predict).\n",
        "x: is the independent variable (the variable used to make the prediction).\n",
        "b₀, b₁, b₂, ..., bₙ: are the coefficients of the polynomial.\n",
        "n: is the degree of the polynomial.\n",
        "ε: is the error term, representing the difference between the predicted value and the actual value.\n",
        "Explanation:\n",
        "\n",
        "Polynomial: The equation represents a polynomial function, which is a sum of terms where each term consists of a coefficient and the independent variable raised to a power.\n",
        "Degree: The highest power of x in the polynomial determines its degree. For example, if n = 2, it's a quadratic polynomial.\n",
        "Flexibility: By increasing the degree of the polynomial, you can model more complex, non-linear relationships between the variables.\n",
        "Overfitting: However, increasing the degree too much can lead to overfitting, where the model fits the training data too closely and performs poorly on new data.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bDnHRRXaNhaT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q27.Can polynomial regression be applied to multiple variables?\n",
        "A-Multiple Independent Variables: Instead of just one independent variable (x), you have multiple independent variables (x₁, x₂, x₃, ...).\n",
        "Polynomial Terms: The model includes not only linear terms of these variables but also interaction terms and higher-order terms (e.g., x₁², x₂³, x₁x₂, x₁x₃, etc.).\n",
        "General Equation (simplified):\n",
        "\n",
        "y = b₀ + b₁x₁ + b₂x₂ + ... + bₙxₙ + b₁₁x₁² + b₂₂x₂² + ... + bₙₙxₙ² + b₁₂x₁x₂ + ... + higher-order terms + ε\n",
        "where:\n",
        "\n",
        "y: is the dependent variable.\n",
        "x₁, x₂, ..., xₙ: are the independent variables.\n",
        "b₀, b₁, b₂, ..., bₙₙ, ...: are the coefficients of the polynomial terms.\n",
        "ε: is the error term.\n",
        "Key Considerations:\n",
        "\n",
        "Complexity: As the number of variables and the degree of the polynomial increase, the model becomes very complex.\n",
        "Overfitting: Overfitting is a significant concern, especially with high-degree polynomials and many variables. Careful model selection and validation are crucial.\n",
        "Interpretation: Interpreting the coefficients of a multivariate polynomial regression model can be challenging due to the interactions between variables.\n",
        "Example:\n",
        "\n",
        "Imagine you're trying to predict house prices. You might use multiple variables like:\n",
        "\n",
        "x₁: Size of the house\n",
        "x₂: Number of bedrooms\n",
        "x₃: Distance to the city center\n",
        "A multivariate polynomial regression model could include terms like:\n",
        "\n",
        "x₁²: The square of the house size (to account for diminishing returns of size)\n",
        "x₁x₂: The interaction between size and number of bedrooms\n",
        "x₃³: The cube of the distance to the city center (to model a non-linear effect of distance)"
      ],
      "metadata": {
        "id": "0BFVPd53Sfms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q28.What are the limitations of polynomial regression?\n",
        "A-1. Overfitting:\n",
        "\n",
        "The Curse of High Degrees: As the degree of the polynomial increases, the model's flexibility grows. This increased flexibility can lead to overfitting, where the model fits the training data too closely, capturing noise and random fluctuations instead of the underlying trend.\n",
        "Poor Generalization: Overfitted models perform poorly on new, unseen data, as they haven't learned the true underlying pattern but rather memorized the quirks of the training set.\n",
        "2. Interpretability Challenges:\n",
        "\n",
        "Complex Equations: Higher-degree polynomials result in complex equations with numerous coefficients. This makes it difficult to understand the relationship between the independent and dependent variables and how each variable contributes to the outcome.\n",
        "Limited Insights: While the model can make predictions, interpreting the coefficients to gain meaningful insights into the underlying process can be challenging.\n",
        "3. Sensitivity to Outliers:\n",
        "\n",
        "Significant Impact: Outliers can have a disproportionately large influence on the fitting of high-degree polynomials, potentially distorting the model and leading to inaccurate predictions.\n",
        "4. Computational Complexity:\n",
        "\n",
        "Increased Calculations: Fitting higher-degree polynomials requires more calculations, which can increase computational time and resource demands, especially with large datasets.\n",
        "5. Choosing the Right Degree:\n",
        "\n",
        "Model Selection Challenge: Determining the optimal degree of the polynomial is crucial. Too low a degree can lead to underfitting, while too high a degree can lead to overfitting. Techniques like cross-validation are often used to find the best degree, but this adds complexity to the modeling process.\n",
        "6. Extrapolation:\n",
        "\n",
        "Unreliable Predictions: Polynomial regression models may not accurately predict values outside the range of the observed data, especially with high-degree polynomials. Extrapolation can lead to unreliable and potentially misleading results.\n",
        "Mitigating Limitations:\n",
        "\n",
        "Regularization: Techniques like Ridge, Lasso, and Elastic Net can help prevent overfitting by penalizing large coefficients.\n",
        "Cross-Validation: Techniques like k-fold cross-validation can help select the optimal degree of the polynomial and assess model performance.\n",
        "Feature Engineering: Transforming the input variables (e.g., using non-linear transformations) can sometimes improve model performance and reduce the need for high-degree polynomials.\n",
        "Visual Inspection: Plotting the data and the fitted polynomial curve can help identify potential overfitting or underfitting issues."
      ],
      "metadata": {
        "id": "2y4-BT-NSua6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q29.What methods can be used to evaluate model fit when selecting the degree of a polynomial?\n",
        "A-1. Visual Inspection\n",
        "\n",
        "Plotting the Data and Fitted Curve: Create a scatter plot of your data and overlay the fitted polynomial curves for different degrees.\n",
        "Look for:\n",
        "Underfitting: The curve doesn't capture the underlying trend in the data.\n",
        "Overfitting: The curve wiggles excessively to fit every data point, including noise.\n",
        "\"Just Right\": The curve smoothly follows the general trend without being overly influenced by outliers.\n",
        "2. Metrics\n",
        "\n",
        "R-squared (R²):\n",
        "Measures the proportion of variance in the dependent variable explained by the model.\n",
        "Higher R² generally indicates a better fit, but it can be misleading with high-degree polynomials that overfit.\n",
        "Adjusted R-squared:\n",
        "Penalizes the model for including extra terms that don't significantly improve the fit.\n",
        "Often a more reliable indicator than R² when comparing models with different degrees.\n",
        "Mean Squared Error (MSE):\n",
        "Measures the average squared difference between the predicted and actual values.\n",
        "Lower MSE indicates a better fit.\n",
        "Root Mean Squared Error (RMSE):\n",
        "The square root of MSE, providing a measure of the average prediction error in the same units as the dependent variable.\n",
        "3. Cross-Validation\n",
        "\n",
        "k-Fold Cross-Validation: Divide the data into k folds.\n",
        "Train the model on k-1 folds and evaluate its performance on the remaining fold.\n",
        "Repeat this process k times, using a different fold for evaluation each time.\n",
        "Calculate the average performance (e.g., MSE) across all folds.\n",
        "This helps estimate how well the model will generalize to new, unseen data.\n",
        "\n",
        "Choose the degree that gives the lowest average validation error.\n",
        "4. Information Criteria\n",
        "\n",
        "Akaike Information Criterion (AIC):\n",
        "A measure of the relative quality of statistical models for a given dataset.\n",
        "Penalizes models with more parameters (higher degrees) to prevent overfitting.\n",
        "Bayesian Information Criterion (BIC):\n",
        "Similar to AIC, but with a stronger penalty for model complexity.\n",
        "5. Regularization\n",
        "\n",
        "Ridge, Lasso, and Elastic Net: These methods add a penalty term to the model's coefficients to discourage overfitting.\n",
        "You can use these techniques with polynomial regression to find the optimal degree while controlling for model complexity.\n",
        "Important Considerations:\n",
        "\n",
        "Balance: Strive for a balance between good fit and model simplicity.\n",
        "Domain Knowledge: Consider the underlying process and whether a high-degree polynomial is realistically expected.\n",
        "Visual Inspection is Key: Always visually inspect the fitted curve alongside the metrics to ensure the model makes sense in the context of your data."
      ],
      "metadata": {
        "id": "q0p6rOZQTFGv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q30.Why is visualization important in polynomial regression?\n",
        "A-Understanding Data Patterns:\n",
        "\n",
        "Identifying Non-Linearity: Visualizing the data helps identify if a linear relationship is insufficient. Scatter plots can reveal curved patterns, indicating the need for polynomial regression.\n",
        "Visualizing Trends: Plots can show trends like U-shapes, curves, or more complex patterns that linear regression cannot capture.\n",
        "Selecting the Degree of the Polynomial:\n",
        "\n",
        "Overfitting/Underfitting: Plotting the fitted polynomial curves for different degrees helps visually assess:\n",
        "Underfitting: The curve doesn't capture the data's trend.\n",
        "Overfitting: The curve wiggles excessively, fitting noise rather than the true pattern.\n",
        "\"Just Right\": The curve smoothly follows the general trend without being overly influenced by outliers.\n",
        "Evaluating Model Fit:\n",
        "\n",
        "Residual Plots: Plotting residuals (differences between predicted and actual values) can reveal patterns that indicate potential issues with the model, such as non-constant variance or non-linearity.\n",
        "Comparing Models: Visualizing the fit of different polynomial degrees allows for a quick comparison of their performance.\n",
        "Communicating Results:\n",
        "\n",
        "Clearer Explanations: Visualizations make it easier to explain the model's findings to others, such as stakeholders or colleagues.\n",
        "Improved Understanding: Plots can help convey the complexity of the relationship between variables more effectively than numerical results alone.\n",
        "In summary, visualization is essential for:\n",
        "\n",
        "Data Exploration: Understanding the nature of the data and identifying the need for polynomial regression.\n",
        "Model Selection: Choosing the appropriate degree of the polynomial.\n",
        "Model Evaluation: Assessing the model's fit and identifying potential issues.\n",
        "Communication: Effectively conveying the model's results and insights."
      ],
      "metadata": {
        "id": "JuVBRwVrTV2C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q31.How is polynomial regression implemented in Python?\n",
        "A-"
      ],
      "metadata": {
        "id": "InV4nGaSTmFp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "# Generate sample data with a quadratic relationship\n",
        "np.random.seed(0)  # For reproducibility\n",
        "x = np.linspace(-5, 5, 100)\n",
        "y = 2 * x**2 + x + 3 + np.random.normal(0, 5, 100)\n",
        "\n",
        "# Create polynomial features with degree 2\n",
        "polynomial_features = PolynomialFeatures(degree=2)\n",
        "x_poly = polynomial_features.fit_transform(x.reshape(-1, 1))\n",
        "\n",
        "# Create and fit the linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(x_poly, y)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(x_poly)\n",
        "\n",
        "# Plot the results\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(x, y, label='Data')\n",
        "plt.plot(x, y_pred, color='red', label='Polynomial Regression (Degree 2)')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.legend()\n",
        "plt.title('Polynomial Regression')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "iBj6vFX9UDpk",
        "outputId": "2404f68b-9862-455e-f38e-61cb9c03a9b8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}